## 개발환경

### BackEnd

- InterlliJ
- Java 11
- spring-boot-jpa
- spring security
- AWS EC2
- MySql 8.0.31-0ubuntu0.20.04.1
- nginx
- jenkins
- docker

---

# 포팅매뉴얼

Docker, Jenkins, SpringBoot, React, Nginx를 이용하여 CICD 무중단 배포

MSA형태로 각 기능의 서비스 별로 다른 브랜치와 젠킨스 프로젝트를 가지고 있음. 

![젠킨스](/uploads/b15bd4750bfdfd71ad2f5839c7bd058e/캡처.PNG)

1. ec2환경에 도커 설치
    
    ```java
    #사전 패키니 gpg Key 다운
    sudo apt update
    sudo apt-get install -y ca-certificates \
        curl \
        software-properties-common \
        apt-transport-https \
        gnupg \
        lsb-release
    
    sudo mkdir -p /etc/apt/keyrings
    curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
    
    echo \
        "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
        $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
    
    #도커 설치
    sudo apt update
    sudo apt install docker-ce docker-ce-cli containerd.io docker-compose
    
    ```
    
2. docker-compose를 사용하여 젠킨스 컨테이너 생성
    
    ```java
    vim docker-compose.yml
    
    #------docker-compose.yml 내부
    version: '3'
    
    services:
        jenkins:
            image: jenkins/jenkins:lts
            container_name: jenkins
            volumes:
                - /var/run/docker.sock:/var/run/docker.sock
                - /jenkins:/var/jenkins_home
            ports:
                - "9090:8080"
            privileged: true
            user: root
    ```
    
3. 젠킨스와 연결하고 깃랩과 연결하여 프론트는 깃랩 메인, 각서비스들은 각자의 서비스 브랜치에 푸쉬할 때마다 빌드 유발하여 자동 배포되도록 함. 
    1. 젠킨스 컨테이너 내부에 도커를 설치하여 젠킨스에서 도커빌드를 하도록 함.
        
        ```java
        sudo docker exec -it jenkins bash
        #사전패키지설치 ,gpg 키 다운로드 등 위와 같이 함
        ```
        
    2. 깃랩에서 각 프로젝트 폴더에 DockerFile을 만들어주기
        
        **스프링 Dockerfile (MSA에 연결된 프로그램들은 아래와 같은 방식으로 이름만 다르게 작성)**
        
        - MSA (O) - apigatewayservice, discoveryservice, businessservice, userservice, gpsservice, s3service
        - MSA (X) - producerservice(8082), consumerservice(8081), chatservice(8080) 은 EXPOSE부분에 포트번호 써서 연결해줌
        
        ```java
        FFROM openjdk:11-jdk
        WORKDIR /var/jenkins_home/workspace/baebooreung/backend/apigatewayservice
        #EXPOSE 8000
        CMD ["./gradlew", "clean", "build"]
        VOLUME /tmp
        ARG JAR_FILE=build/libs/apigatewayService.jar
        COPY ${JAR_FILE} apigatewayService.jar
        ENTRYPOINT ["java","-jar","apigatewayService.jar"]
        ENV TZ=Asia/Seoul
        RUN apt-get install -y tzdata
        ```
        
        ******************************************************************SPEACH TO TEXT SERVICE Dockerfile******************************************************************
        
        ```bash
        # 파이썬 이미지를 기반으로 함
        FROM python:3.8
        WORKDIR /var/jenkins_home/workspace/baebooreung/backend/speechtotextservice
        COPY . .
        RUN pip3 install flask
        RUN pip3 install --upgrade google-cloud-storage
        RUN pip3 install google-cloud-speech
        
        EXPOSE 5000
        
        CMD python3 ./app.py
        ```
        
        **리액트 Dockerfile**
        
        ```java
        FROM node:16.17.0 as build-stage
        WORKDIR /var/jenkins_home/workspace/yeobo/frontend/yeobo
        COPY package*.json ./
        RUN npm install
        COPY . .
        RUN npm run build
        FROM nginx:stable-alpine as production-stage
        
        COPY --from=build-stage /var/jenkins_home/workspace/yeobo/frontend/yeobo/build usr/share/nginx/html
        COPY --from=build-stage /var/jenkins_home/workspace/yeobo/frontend/yeobo/deploy_conf/nginx.conf /etc/nginx/conf.d/default.conf
        EXPOSE 80
        CMD ["nginx", "-g","daemon off;"]
        ```
        
    3. 젠킨스에서 도커파일을 이용해 도커 이미지 만들기
        
        자동 빌드하고 빌드 단계로 각각 tar파일로 만들어서 저장하기
        
        ```java
        docker image prune -a --force
        mkdir -p /var/jenkins_home/images_tar
        
        cd /var/jenkins_home/workspace/yeobo/frontend/yeobo/
        docker build -t react .
        docker save react > /var/jenkins_home/images_tar/react.tar
        ```
        
        아래와 같은 방식으로 서비스들 모두 만들어줌
        
        ```bash
        chmod +x ./gradlew
        ./gradlew clean
        ./gradlew bootJar 
        docker build -t apigateway .
        docker save apigateway > /var/jenkins_home/images_tar/apigateway.tar
        ```
        
    
    d. 젠킨스에서 ssh 명령어 전송을 통해 빌드한 도커 이미지를 이용하여 도커 컨테이너 생성하기
    
    젠킨스에서 pem키를 vscode로 열어서 SSH Server의 키를 넣어주기
    
    **빌드 후 조치 Send build artifacts over SSH** 
    
    ```bash
    sudo docker load < /jenkins/images_tar/react.tar
    sudo docker load < /jenkins/images_tar/chat-service.tar
    
    if (sudo docker ps | grep "react"); then sudo docker stop react; fi
    if (sudo docker ps | grep "chat-service"); then sudo docker stop chat-service; fi
    
    sudo docker run -it -d --rm -p 3000:80 -p 443:443 --name react react
    echo "Run React"
    
    sudo docker run -it -d --rm -p 8080:8080 --name chat-service chat-service -v /jenkins:/var/jenkins_home
    echo "Run chat service"
    ```
    
    ```bash
    sudo docker load < /jenkins/images_tar/apigateway.tar
    
    if (sudo docker ps | grep "apigateway"); then sudo docker stop apigateway; fi
    
    sudo docker run -it -d -p 8000:8000 --network baebooreung-network -e "eureka.client.serviceUrl.defaultZone=http://discovery:8761/eureka/"  --name apigateway apigateway
    echo "Run apigateway service"
    ```
    
    ```bash
    sudo docker load < /jenkins/images_tar/business-service.tar
    
    if (sudo docker ps | grep "business-service"); then sudo docker stop business-service; fi
    
    sudo docker run -it -d --rm --network baebooreung-network -e "eureka.client.serviceUrl.defaultZone=http://discovery:8761/eureka/" --name business-service business-service
    echo "Run business service"
    ```
    
    ```bash
    sudo docker load < /jenkins/images_tar/checkin-service.tar
    
    if (sudo docker ps | grep "checkin-service"); then sudo docker stop checkin-service; fi
    
    sudo docker run --rm -it -d -p 8084:8084 --name checkin-service checkin-service -v /jenkins:/var/jenkins_home
    echo "Run checkin service"
    ```
    
    각 도커 이미지 파일이 있는 곳에서 load 받아서 도커 컨테이너로 생성하기. 필요에 따라 바인드 마운트 혹은 포트번호 입력 
    
    MSA통신이 필요한 곳에서는 baebooreung network로 연결하고, application.properties에서 localhost로 돌아가던 것을 network의 이름으로 연결시켜줌.
    
    (이름만 동일하고 비슷한 내용인 것은 이하 생략)
    

1. mysql 연결
    1. 서버에 mariaDB 설치
        
        ```java
        sudo apt-get update
        sudo apt-get install mysq-server
        ```
        
    2. 외부 접근용 계정 권한 설정
        
        ```bash
        # mysql 들어가는 명령어 2가지
        sudo mysql # 관리자 권한으로 패스워드 없이 입장
        mysql -u root -p # root 계정을 password 쳐서 들어간다 (패스워드 : yeobo)
        ```
        
        ```sql
        # mariaDB 내부 콘솔
        
        # 유저 생성하기 (ID:아이디 / PW : 비밀번호)
        CREATE USER '아이디'@'%' IDENTIFIED BY '비밀번호';
        
        # 새로고침
        flush privileges;
        
        # 쿼리문으로 확인하기
        SELECT * FROM mysql.USER;
        
        # yeobo 계정에 모든 권한을 부여
        GRANT ALL PRIVILEGES ON *.* TO '아이디'@'%' IDENTIFIED BY '비밀번호';
        GRANT ALL PRIVILEGES ON *.* TO '아이디'@'localhost' IDENTIFIED BY '비밀번호';
        
        # 새로고침
        flush privileges;
        
        # 권한 확인하기
        SHOW GRANTS FOR yeobo@'%';
        SHOW GRANTS FOR yeobo@'localhost';
        ```
        
        ```bash
        # db 재시작
        sudo systemctl restart mysqld
        ```
        
    
    ```bash
    # 별개로 한국 시간으로 우분투 시스템 설정하는 법
    sudo timedatectl set-timezone 'Asia/Seoul'
    sudo systemctl restart mysqld # mariaDB 재시작
    ```
    
    1. 스프링 [application.properties](http://application.properties) 설정 변경
        
        ```java
        # MySQL
        spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
        spring.datasource.url=jdbc:mysql://k7c207.p.ssafy.io:3306/93pro?useSSL=false&useUnicode=true&serverTimezone=Asia/Seoul
        spring.datasource.username=baebooreung
        spring.datasource.password=baebooreung93pro
        ```
        
2. SSL 발급해서 HTTPS로 변경
    
    ```bash
    apt-get install snapd -y  #snap 설치
    snap version #잘 설치됐는지 버전 확인
    ```
    
    ```bash
    #snap을 통한 certbot 설치
    sudo snap refresh core
    
    sudo snap install --classic certbot
    
    sudo ln -s /snap/bin/certbot /usr/bin/certbot
    ```
    
    ```bash
    #certbot 통한 ssl 발급
    sudo certbot certonly --standalone
    # -> 이메일 입력(자신이 가진 인증가능한 이메일이면 상관 X), 도메인 입력
    ```
    
    certificate 저장 장소와 key 저장장소를 가지고 있다가 nginx.conf 파일에서 써줘야함
    
    nginx.conf에 ssl 관련 추가
    
    ```java
    ssl on;
    ssl_certificate /etc/letsencrypt/live/j7c103.p.ssafy.io/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/j7c103.p.ssafy.io/privkey.pem;
    ```
    

**nginx 경로 설정**

우분투 jenkins/workspace/yeobo/frontend/yeobo/deploy_conf

(경로 설정 시 포트가 열려있으면 안되므로 컨테이너를 중단시키고 하기)

```java
sudo vim nginx.conf
```

**nginx.conf**파일

```java
upstream backend{
        ip_hash;
        server k7c207.p.ssafy.io:8080;
}

upstream msa{
	ip_hash;
	server k7c207.p.ssafy.io:8000;
}

server {

    listen 80;
    listen [::]:80;
    server_name  k7c207.p.ssafy.io;
    # 80(http)로 들어오는 url 전부 https(443)으로 리다이렉트
    return 301 https://k7c207.p.ssafy.io$request_uri;
#    return 301 https://www.baebooreung.com$request_uri;
}

server {
    listen 443 ssl;
    listen [::]:443 ssl;
    server_name k7c207.p.ssafy.io;

    #access_log  /var/log/nginx/host.access.log  main;
		
		# 인증서 위치 알려주는 명령어
    ssl on;
    ssl_certificate /etc/letsencrypt/live/k7c207.p.ssafy.io/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/k7c207.p.ssafy.io/privkey.pem;
#    ssl_certificate /etc/letsencrypt/live/www.baebooreung.com/fullchain.pem;
#    ssl_certificate_key /etc/letsencrypt/live/www.baebooreung.com/privkey.pem;

   				
   location / {
    
        root   /usr/share/nginx/html;
        index  index.html index.htm;
	try_files $uri $uri/ /index.html;
 #       proxy_pass http://msa/;
        proxy_redirect     off;
        proxy_set_header   Host $host;
        proxy_set_header   X-Real-IP $remote_addr;
        proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;
 
	 # WebSocket support
#         proxy_http_version 1.1;
#         proxy_set_header Upgrade $http_upgrade;
#         proxy_set_header Connection "upgrade"; 

#	add_header 'Access-Control-Allow-Origin' '*';
#        proxy_pass http://localhost:3000/;  
        
   }

   location /speechtotext-service {
       proxy_pass http://k7c207.p.ssafy.io:5000/speechtotext-service;       
   }	
       
    # k7c207.p.ssafy.io'/api'
    location /api {
        proxy_pass http://backend/;
        proxy_redirect     off;
        proxy_set_header   Host $host;
        proxy_set_header   X-Real-IP $remote_addr;
        proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;

    # WebSocket support
	proxy_http_version 1.1;
	proxy_set_header Upgrade $http_upgrade;
	proxy_set_header Connection "upgrade";
    }
				
    location /business-service {
	proxy_pass http://msa/;
	proxy_redirect	off;
	proxy_set_header	Host $host;
	proxy_set_header	X-Real-IP $remote_addr;
	proxy_set_header	X-Forwarded-For $proxy_add_x_forwarded_for;
	
    }

    location /user-service {
	proxy_pass https://msa/;
	proxy_redirect off;
	proxy_set_header	Host $host;
	proxy_set_header	X-Real_IP $remote_addr;
	proxy_set_header	X-Forwarded-For $proxy_add_x_forwarded_for;
    }

    location /s3-service {
	proxy_pass https://msa/;
        proxy_redirect off;
        proxy_set_header        Host $host;
        proxy_set_header        X-Real_IP $remote_addr;
        proxy_set_header        X-Forwarded-For $proxy_add_x_forwarded_for;
    }

    location /chat-service {
	 proxy_pass http://msa/;
        proxy_redirect  off;
        proxy_set_header        Host $host;
        proxy_set_header        X-Real-IP $remote_addr;
        proxy_set_header        X-Forwarded-For $proxy_add_x_forwarded_for;

	# WebSocket support
#        proxy_http_version 1.1;
#        proxy_set_header Upgrade $http_upgrade;
#        proxy_set_header Connection "upgrade";

}	
	#error_page  404              /404.html;

    # redirect server error pages to the static page /50x.html
    #
    error_page   500 502 503 504  /50x.html;
    location = /50x.html {
        root   /usr/share/nginx/html;
    }

    # proxy the PHP scripts to Apache listening on 127.0.0.1:80
    #
    #location ~ \.php$ {
    #    proxy_pass   http://127.0.0.1;
    #}

    # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
    #
    #location ~ \.php$ {
    #    root           html;
    #    fastcgi_pass   127.0.0.1:9000;
    #    fastcgi_index  index.php;
    #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;
    #    include        fastcgi_params;
    #}

    # deny access to .htaccess files, if Apache's document root
    # concurs with nginx's one
    #
    #location ~ /\.ht {
    #    deny  all;
    #}
}
```

**SSL인증서를 spring boot에서 필요한 형식(PKCS12)로 변환**

```bash
openssl pkcs12 -export -in fullchain.pem -inkey privkey.pem -out keystore.p12 -name tomcat -CAfile chain.pem -caname root
```

위의 명령어를 pem키가 없는 곳에서 입력하기

 (`root@ip-172-26-8 -158:/etc/letsencrypt/live/j7c103.p.ssafy.io#`   여기서)

winscp 설치하여 keystore.p12 파일을 /src/main/resources에 이동

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a87f39bb-3f91-4431-8e68-4ab7222b1214/Untitled.png)

spring [application.properties](http://application.properties) 파일 수정

## Chat Server + Redis 구현

### Redis 없이 Websocket과 Stomp만으로 채팅 구현

- **서버를 재시작 할 때마다 채팅방 정보들이 리셋됨**
    - 채팅방의 메인 저장소가 없으므로 서버의 메모리에 적재된 채팅방은 서버를 재시작할 때마다 초기화되는 이슈가 있음
    - DB를 이용하거나 다른 저장소를 이용하여 채팅방이 계속 유지되도록 처리가 필요하다.
- **채팅서버가 여러대이면 서버간 채팅방을 공유할 수가 없음**
    - 현재 채팅방은 Websocket과 Stomp pub/sub를 이용하여 구현하였다.
    - 이러한 구조는 pub/sub가 발생한 서버 내에서만 메시지를 주고 받는 것이 가능하다.
        - 구독 대상인 채팅방(topic)이 생성된 서버 안에서만 유효하므로 다른 서버로 접속한 클라이언트는 해당 채팅방이 보이지도 않고, 채팅방 구독도 불가능하다.
        - 구독 대상이 여러 서버에 접근할 수 있도록 개선이 필요
    - 공통으로 사용할 수 있는 pub/sub 시스템을 구축하고 모든 서버들이 해당 시스템을 통하여 pub/sub 메시지를 주고 받을 수 있어야한다.

### Redis 발행/구독 모델 구현을 위한 서비스 생성

- Redis에서는 공통 주제(Topic)에 대하여 구독자(Subscriber)에게 메시지를 발행(publish)할 수 있는 기능이 있다.
    - pub/sub
- 채팅방에서는 redis의 topic을 채팅방이라고 가정하고, pub/sub는 대화를 하거나 대화를 보는 행위이다.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d9b6bf0f-d442-4dcc-aba8-09beaa7a7ade/Untitled.png)

- Websocket의 경우 http 프로토콜로 접속한 후에 Websocket 프로토콜로 upgrade 하는 과정을 거친다.
- `/jenkins/workspace/baebooreung/frontend/deploy_conf`
- `sudo vim nginx.conf`
- `/jenkins/workspace/baebooreung/backend/deploy_conf`

```bash
upstream backend{
        ip_hash;
        server k7c207.p.ssafy.io:8080;
}

upstream msa{
        ip_hash;
        server k7c207.p.ssafy.io:8000;
}

server {
    listen 80;
    listen [::]:80;
    server_name  k7c207.p.ssafy.io;
    # 80(http)로 들어오는 url 전부 https(443)으로 리다이렉트
    return 301 https://k7c207.p.ssafy.io$request_uri;
}

server {
    listen 443 ssl;
    listen [::]:443 ssl;
    server_name k7c207.p.ssafy.io;

    #access_log  /var/log/nginx/host.access.log  main;

                # 인증서 위치 알려주는 명령어
    ssl on;
    ssl_certificate /etc/letsencrypt/live/k7c207.p.ssafy.io/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/k7c207.p.ssafy.io/privkey.pem;

    location / {
        root   /usr/share/nginx/html;
        index  index.html index.htm;
        try_files $uri $uri/ /index.html;
        #proxy_pass http://msa/;
        #proxy_redirect     off;
        #proxy_set_header   Host $host;
        #proxy_set_header   X-Real-IP $remote_addr;
        #proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;
}
                                # k7c207.p.ssafy.io'/api'
    location /api {
        proxy_pass http://backend/;
        proxy_redirect     off;
        proxy_set_header   Host $host;
        proxy_set_header   X-Real-IP $remote_addr;
        proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;

    # WebSocket support
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }

        #error_page  404              /404.html;

    # redirect server error pages to the static page /50x.html
    #
    error_page   500 502 503 504  /50x.html;
    location = /50x.html {
        root   /usr/share/nginx/html;
    }

    # proxy the PHP scripts to Apache listening on 127.0.0.1:80
    #
    #location ~ \.php$ {
    #    proxy_pass   http://127.0.0.1;
    #}

    # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
    #
    #location ~ \.php$ {
    #    root           html;
    #    fastcgi_pass   127.0.0.1:9000;
    #    fastcgi_index  index.php;
    #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;
    #    include        fastcgi_params;
```

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/65ef282f-04c0-4124-8610-54f470be09b6/Untitled.png)

```
// 재시작
$ sudo service nginx restart
$ sudo systemctl restart nginx
$ sudo /etc/init.d/nginx restart
```

## kafka 브로커 서버와 주키퍼 구축

1. docker 설치

```python
# 1. 기존에 설치된 docker 패키지 제거
$ sudo apt-get remove docker docker-engine docker.io

# 2. apt-update 최신상태인지 체크
$ sudo apt-get update

# 3. apt를 사용해 docker 설치 진행 -> 설치과정에서 y 선택
$ sudo apt install docker.io

# 4. docker 모든 종속성 패키지도 함께 설치
$ sudo snap install docker

# 5. 제대로 설치되었는지 docker version 확인하기
$ docker --version
```

2. docker 설치 후 권한부여

- 기본적으로 Docker 설치하면 권리자 권한 필요 → sudo 명령어 없이 docker 사용 가능

```python
# docker group 추가
$ sudo groupadd docker

# docker group에 현재의 사용자 추가
$ sudo usermod -aG docker $USER
```

1. docker-compose 설치

```python
# 1. docker compose 설치
$ sudo curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose

# 2. docker-compose에 실행 권한 부여
$ sudo chmod +x /usr/local/bin/docker-compose

# 3. 심볼릭 링크 설정
$ ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose

# 3. docker-compose 설치확인
$ docker-compose --version
```

## docker-compose 관련 명령어

```python
# 모든 컨테이너 생성 및 실행
$ docker-compose -f docker-compose.yml up -d

# 모든 컨테이너 제거
$ docker-compose down --rmi all
```

1. kafka broker 서버와 zookeeper docker-compose로 구축
- docker-compose.yml 파일

```python
version: '2'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:5.0.0
    privileged: true
    ports:
      - 32181:32181
    environment:
      ZOOKEEPER_CLIENT_PORT: 32181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:5.0.0
    ports:
      - 29092:29092
    links:
      - zookeeper
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:32181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://k7c2071.p.ssafy.io:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
```

1. kafka 서버 모니터링
- docker-compose.yml

```python
version: '2'
services:
  kafka-ui:
    image: provectuslabs/kafka-ui
    container_name: kafka-ui
    ports:
      - "8989:8080"
    restart: always
    environment:
      - KAFKA_CLUSTERS_0_NAME=localhost
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=k7c2071.p.ssafy.io:29092
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper:32181
```

## MSA 관련 배포

### Bridge network 설치

- 각각 개별적인 컨테이너들이 ip address를 통해 원래 통신하지만
    
    docker container를 만들어서 하다보면 ip address가 바뀌는 경우가 있음
    
    → 컨테이너 이름으로 통신할 수 있도록 하기 위해 bridge network 사용하여 같은 
    

```bash
docker network create baebooreung-network
```

```bash
잘 설치되었는지 확인
ubuntu@ip-172-26-4-204:~$ docker network ls
NETWORK ID     NAME                                           DRIVER    SCOPE
ebd6847f9b02   baebooreung-network                            bridge    local
04da514baecd   bridge                                         bridge    local
dca7ba58280b   confluentinc-kafka-connect-jdbc-1060_default   bridge    local
62d005df7e71   connect_default                                bridge    local
29ead25d5896   host                                           host      local
173b04e42bab   kafka-connector_default                        bridge    local
588c383fb3f5   kafka_default                                  bridge    local
8335b04e355a   none                                           null      local
4e55c647acda   redis-net                                      bridge    local
df7319bbe187   ubuntu_default                                 bridge    local
```

```bash
네트워크 상세정보 보기
ubuntu@ip-172-26-4-204:~$ docker network inspect baebooreung-network
[
    {
        "Name": "baebooreung-network",
        "Id": "ebd6847f9b02dcdd994e7391afbd72a908d2a6c0baff8c229508d48b61705e11",
        "Created": "2022-11-01T02:44:34.347061771Z",
        "Scope": "local",
        "Driver": "bridge",
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
            "Options": {},
            "Config": [
                {
                    "Subnet": "172.24.0.0/16",
                    "Gateway": "172.24.0.1"
                }
            ]
        },
        "Internal": false,
        "Attachable": false,
        "Ingress": false,
        "ConfigFrom": {
            "Network": ""
        },
        "ConfigOnly": false,
        "Containers": {
            "74e4ed2b24afa52c7ff978d1eb6c88a07aa22f7cbfdb309f46bf866e9a3e9834": {
                "Name": "discovery",
                "EndpointID": "6ff6c594695a51b1a1506b2f43569ce8a7f9b3f74f25d5ec9f800424f3ba9704",
                "MacAddress": "02:42:ac:18:00:03",
                "IPv4Address": "172.24.0.3/16",
                "IPv6Address": ""
            },
            "81c9e9f3c0604d8cabb96e033e75ef2434d59da39bd033bbe0f357538f2ae91d": {
                "Name": "apigateway",
                "EndpointID": "d748a6dd5c3799f1c3e8dbb23c9cebb6aeb5aa3e6a7ad361863465b657fc2dee",
                "MacAddress": "02:42:ac:18:00:05",
                "IPv4Address": "172.24.0.5/16",
                "IPv6Address": ""
            },
            "aaf3df2a759d80f3d56b8bc797492edc5cfe99872d212c22e1237f2ba361e770": {
                "Name": "business-service",
                "EndpointID": "1b1b662d0f27c7412e6d183acb1ee879e412208103b6ecfb2d666158ea04adf1",
                "MacAddress": "02:42:ac:18:00:04",
                "IPv4Address": "172.24.0.4/16",
                "IPv6Address": ""
            },
            "b5d0ccb478f7b7a2d09612cb440c946e17c0de008dbe0c80b8a34cfbbee789d7": {
                "Name": "user-service",
                "EndpointID": "665f34b588d41e7248e8d706c6edcafa9b9fbb22b89a71432cee5efdd573f2fc",
                "MacAddress": "02:42:ac:18:00:02",
                "IPv4Address": "172.24.0.2/16",
                "IPv6Address": ""
            },
            "cb66cbe9d784814f7fd4fd3f4e7558f5bc053b9929a445483737023b1599d752": {
                "Name": "s3-service",
                "EndpointID": "6e012793e3366d1263594844f161392d468d5f43021e67c22ac9e473086bc94f",
                "MacAddress": "02:42:ac:18:00:07",
                "IPv4Address": "172.24.0.7/16",
                "IPv6Address": ""
            },
            "e81550e96151fa8663eaedae32ce3c1e086391a07c541bfc65f2834b2585868e": {
                "Name": "gps-service",
                "EndpointID": "bf1886bbf88029acbdf78569b230ac6bdf2daa6191706c5e9f08f5fb55b439f9",
                "MacAddress": "02:42:ac:18:00:06",
                "IPv4Address": "172.24.0.6/16",
                "IPv6Address": ""
            }
        },
        "Options": {},
        "Labels": {}
    }
]
```
